###
import pandas as pd
from tqdm import tqdm
import sys, logging

import requests

from pytube import Channel, YouTube

from youtube_transcript_api import YouTubeTranscriptApi as YT
import scrapetube as scrapeYT
###
# base_output = './transcripts'
input_srcs = 'channel_video_ids.csv'
###
df = pd.read_csv(input_srcs, delimiter=',')
###
result_df = None
# Loop through each row in the original DataFrame
for index, row in df.iterrows():
    # Initialize an empty DataFrame to store the results
    result_df = pd.DataFrame(columns=['video_id', 'published_date', 'channel_name', 'channel_category', 'channel_id', 'is_autogenerated','transcription'])
    video_ids = df.loc[index, 'video_ids'][1:-1].replace("'", '').split(', ')
    # Loop through the video_ids
    for video_id in tqdm(video_ids,desc=row['name']):
      is_gen=None
      transcript_text = None
      publish_date = None
      video_title = None
      video_df = None
      try:
        # Create a YouTube object
        yt = YouTube(f'https://www.youtube.com/watch?v={video_id}')
        # Extract the video's publish date
        publish_date = yt.publish_date
      except:
        print('publish date error')
      try:
        # Extract the video title
        response = requests.get(f'http://noembed.com/embed?url=http%3A//www.youtube.com/watch%3Fv%3D{video_id}')
        data = response.json()
        video_title = data['title']
      except:
        print('title error')
      try:
        transcript_list = YT.list_transcripts(video_id)
        transcript = transcript_list.find_generated_transcript(['es'])
        is_gen = transcript.is_generated
        transcript_dic = transcript.fetch()
        transcript_text = ' '.join([entry['text'] for entry in transcript_dic])
      except Exception as e:
        print('No Transcription Abveilable')

      if not(video_title and publish_date and is_gen and transcript_text):
        continue
      # Create a new DataFrame for the current video_id
      video_df = pd.DataFrame({
          'video_id': [video_id],
          'published_date': [publish_date],
          'channel_name': [row['name']],
          'channel_category': [row['category']],
          'channel_id': [row['id']],
          'is_autogenerated': [is_gen],
          'transcription': [transcript_text]
      })
      print('Data collected!')

      if '2017' in publish_date:
        break

      # Append the new DataFrame to the result_df
      result_df = pd.concat([result_df, video_df], ignore_index=True)
    result_df.to_csv(f'{row["name"]}-transcripts.csv',sep=',')
    result_df = None
